{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "VT9iQRs5xYdM"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "Rg7PKEQkwYPQ"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/fertilizer.xlsx\")"
      ],
      "metadata": {
        "id": "MLwLC8QUxkSZ"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1TvvXuD3xkjp",
        "outputId": "0d5b1cf7-f0f2-4c03-94c7-0be65b7080e6"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Area_code     Area  Item_code                Item  Element_code  \\\n",
              "0          1  Armenia       4007  Ammonia, anhydrous          5610   \n",
              "1          1  Armenia       4007  Ammonia, anhydrous          5610   \n",
              "2          1  Armenia       4007  Ammonia, anhydrous          5610   \n",
              "3          1  Armenia       4007  Ammonia, anhydrous          5610   \n",
              "4          1  Armenia       4007  Ammonia, anhydrous          5610   \n",
              "\n",
              "           Element  Year_code  Year    Unit   Value Flag  \n",
              "0  Import Quantity       2006  2006  tonnes    0.01   Qm  \n",
              "1  Import Quantity       2007  2007  tonnes   32.88   Qm  \n",
              "2  Import Quantity       2008  2008  tonnes   62.19   Qm  \n",
              "3  Import Quantity       2009  2009  tonnes  119.93   Qm  \n",
              "4  Import Quantity       2010  2010  tonnes   94.17   Qm  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3309c7ec-3304-48bf-b8a5-e6a0711c6f4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area_code</th>\n",
              "      <th>Area</th>\n",
              "      <th>Item_code</th>\n",
              "      <th>Item</th>\n",
              "      <th>Element_code</th>\n",
              "      <th>Element</th>\n",
              "      <th>Year_code</th>\n",
              "      <th>Year</th>\n",
              "      <th>Unit</th>\n",
              "      <th>Value</th>\n",
              "      <th>Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Armenia</td>\n",
              "      <td>4007</td>\n",
              "      <td>Ammonia, anhydrous</td>\n",
              "      <td>5610</td>\n",
              "      <td>Import Quantity</td>\n",
              "      <td>2006</td>\n",
              "      <td>2006</td>\n",
              "      <td>tonnes</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Qm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Armenia</td>\n",
              "      <td>4007</td>\n",
              "      <td>Ammonia, anhydrous</td>\n",
              "      <td>5610</td>\n",
              "      <td>Import Quantity</td>\n",
              "      <td>2007</td>\n",
              "      <td>2007</td>\n",
              "      <td>tonnes</td>\n",
              "      <td>32.88</td>\n",
              "      <td>Qm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Armenia</td>\n",
              "      <td>4007</td>\n",
              "      <td>Ammonia, anhydrous</td>\n",
              "      <td>5610</td>\n",
              "      <td>Import Quantity</td>\n",
              "      <td>2008</td>\n",
              "      <td>2008</td>\n",
              "      <td>tonnes</td>\n",
              "      <td>62.19</td>\n",
              "      <td>Qm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Armenia</td>\n",
              "      <td>4007</td>\n",
              "      <td>Ammonia, anhydrous</td>\n",
              "      <td>5610</td>\n",
              "      <td>Import Quantity</td>\n",
              "      <td>2009</td>\n",
              "      <td>2009</td>\n",
              "      <td>tonnes</td>\n",
              "      <td>119.93</td>\n",
              "      <td>Qm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Armenia</td>\n",
              "      <td>4007</td>\n",
              "      <td>Ammonia, anhydrous</td>\n",
              "      <td>5610</td>\n",
              "      <td>Import Quantity</td>\n",
              "      <td>2010</td>\n",
              "      <td>2010</td>\n",
              "      <td>tonnes</td>\n",
              "      <td>94.17</td>\n",
              "      <td>Qm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3309c7ec-3304-48bf-b8a5-e6a0711c6f4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3309c7ec-3304-48bf-b8a5-e6a0711c6f4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3309c7ec-3304-48bf-b8a5-e6a0711c6f4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hbPVyochrXw",
        "outputId": "79ce2083-ef1c-48b7-949a-fe31dc0614f9"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 146550 entries, 0 to 146549\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Area_code     146550 non-null  int64  \n",
            " 1   Area          146550 non-null  object \n",
            " 2   Item_code     146550 non-null  int64  \n",
            " 3   Item          146550 non-null  object \n",
            " 4   Element_code  146550 non-null  int64  \n",
            " 5   Element       146550 non-null  object \n",
            " 6   Year_code     146550 non-null  int64  \n",
            " 7   Year          146550 non-null  int64  \n",
            " 8   Unit          146550 non-null  object \n",
            " 9   Value         146550 non-null  float64\n",
            " 10  Flag          146550 non-null  object \n",
            "dtypes: float64(1), int64(5), object(5)\n",
            "memory usage: 12.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "lyz52yYOjTSp",
        "outputId": "9298ac45-f008-4a15-8d99-9a9f857384f2"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 count          mean            std     min        25%  \\\n",
              "Area_code     146550.0    129.388878      73.241525     1.0    67.0000   \n",
              "Item_code     146550.0   4014.247472       9.006368  4001.0  4006.0000   \n",
              "Element_code  146550.0   5665.826905     212.072730  5157.0  5610.0000   \n",
              "Year_code     146550.0   2009.742143       4.543515  2002.0  2006.0000   \n",
              "Year          146550.0   2009.742143       4.543515  2002.0  2006.0000   \n",
              "Value         146550.0  98259.402706  689518.845901 -1043.0    50.8825   \n",
              "\n",
              "                   50%        75%          max  \n",
              "Area_code      121.000    198.000       276.00  \n",
              "Item_code     4014.000   4022.000      4030.00  \n",
              "Element_code  5622.000   5910.000      5922.00  \n",
              "Year_code     2010.000   2014.000      2017.00  \n",
              "Year          2010.000   2014.000      2017.00  \n",
              "Value         1087.745  16683.455  49046666.67  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a0d17b4-a4a2-48ad-aada-91d0de691f70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Area_code</th>\n",
              "      <td>146550.0</td>\n",
              "      <td>129.388878</td>\n",
              "      <td>73.241525</td>\n",
              "      <td>1.0</td>\n",
              "      <td>67.0000</td>\n",
              "      <td>121.000</td>\n",
              "      <td>198.000</td>\n",
              "      <td>276.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Item_code</th>\n",
              "      <td>146550.0</td>\n",
              "      <td>4014.247472</td>\n",
              "      <td>9.006368</td>\n",
              "      <td>4001.0</td>\n",
              "      <td>4006.0000</td>\n",
              "      <td>4014.000</td>\n",
              "      <td>4022.000</td>\n",
              "      <td>4030.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Element_code</th>\n",
              "      <td>146550.0</td>\n",
              "      <td>5665.826905</td>\n",
              "      <td>212.072730</td>\n",
              "      <td>5157.0</td>\n",
              "      <td>5610.0000</td>\n",
              "      <td>5622.000</td>\n",
              "      <td>5910.000</td>\n",
              "      <td>5922.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Year_code</th>\n",
              "      <td>146550.0</td>\n",
              "      <td>2009.742143</td>\n",
              "      <td>4.543515</td>\n",
              "      <td>2002.0</td>\n",
              "      <td>2006.0000</td>\n",
              "      <td>2010.000</td>\n",
              "      <td>2014.000</td>\n",
              "      <td>2017.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Year</th>\n",
              "      <td>146550.0</td>\n",
              "      <td>2009.742143</td>\n",
              "      <td>4.543515</td>\n",
              "      <td>2002.0</td>\n",
              "      <td>2006.0000</td>\n",
              "      <td>2010.000</td>\n",
              "      <td>2014.000</td>\n",
              "      <td>2017.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Value</th>\n",
              "      <td>146550.0</td>\n",
              "      <td>98259.402706</td>\n",
              "      <td>689518.845901</td>\n",
              "      <td>-1043.0</td>\n",
              "      <td>50.8825</td>\n",
              "      <td>1087.745</td>\n",
              "      <td>16683.455</td>\n",
              "      <td>49046666.67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a0d17b4-a4a2-48ad-aada-91d0de691f70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a0d17b4-a4a2-48ad-aada-91d0de691f70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a0d17b4-a4a2-48ad-aada-91d0de691f70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK9-HBSOftjS",
        "outputId": "73a23e22-441c-4cc4-93e3-55565668e8fb"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Area_code', 'Area', 'Item_code', 'Item', 'Element_code', 'Element',\n",
              "       'Year_code', 'Year', 'Unit', 'Value', 'Flag'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Area_code','Item_code','Element_code','Year_code',\"Flag\"],axis =1,inplace =True)"
      ],
      "metadata": {
        "id": "YVDcSCNjhwRb"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.get_dummies(df,columns=['Area','Element','Item','Unit'],drop_first=True)\n",
        "print(df1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvaBPClVlJms",
        "outputId": "88d47d5d-2c99-4ea4-a7b9-0a4d0f29ea05"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(146550, 175)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILkFxRhdt_xR",
        "outputId": "83c0281b-e5be-4af2-8016-8b32d29289ab"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Year', 'Value', 'Area_Albania', 'Area_Algeria', 'Area_Angola',\n",
              "       'Area_Argentina', 'Area_Armenia', 'Area_Australia', 'Area_Austria',\n",
              "       'Area_Azerbaijan',\n",
              "       ...\n",
              "       'Item_Phosphate rock',\n",
              "       'Item_Potassium chloride (muriate of potash) (MOP)',\n",
              "       'Item_Potassium nitrate',\n",
              "       'Item_Potassium sulphate (sulphate of potash) (SOP)',\n",
              "       'Item_Sodium nitrate', 'Item_Superphosphates above 35%',\n",
              "       'Item_Superphosphates, other', 'Item_Urea',\n",
              "       'Item_Urea and ammonium nitrate solutions (UAN)', 'Unit_tonnes'],\n",
              "      dtype='object', length=175)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "Bj8J4vxtvF5z",
        "outputId": "292ccdf9-5e8e-49dd-f7f1-c07e6e328e0f"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year  Value  Area_Albania  Area_Algeria  Area_Angola  Area_Argentina  \\\n",
              "0  2006   0.01             0             0            0               0   \n",
              "\n",
              "   Area_Armenia  Area_Australia  Area_Austria  Area_Azerbaijan  ...  \\\n",
              "0             1               0             0                0  ...   \n",
              "\n",
              "   Item_Phosphate rock  Item_Potassium chloride (muriate of potash) (MOP)  \\\n",
              "0                    0                                                  0   \n",
              "\n",
              "   Item_Potassium nitrate  Item_Potassium sulphate (sulphate of potash) (SOP)  \\\n",
              "0                       0                                                  0    \n",
              "\n",
              "   Item_Sodium nitrate  Item_Superphosphates above 35%  \\\n",
              "0                    0                               0   \n",
              "\n",
              "   Item_Superphosphates, other  Item_Urea  \\\n",
              "0                            0          0   \n",
              "\n",
              "   Item_Urea and ammonium nitrate solutions (UAN)  Unit_tonnes  \n",
              "0                                               0            1  \n",
              "\n",
              "[1 rows x 175 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14cc0bff-adb8-4844-b7f4-4b640c2a0382\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Value</th>\n",
              "      <th>Area_Albania</th>\n",
              "      <th>Area_Algeria</th>\n",
              "      <th>Area_Angola</th>\n",
              "      <th>Area_Argentina</th>\n",
              "      <th>Area_Armenia</th>\n",
              "      <th>Area_Australia</th>\n",
              "      <th>Area_Austria</th>\n",
              "      <th>Area_Azerbaijan</th>\n",
              "      <th>...</th>\n",
              "      <th>Item_Phosphate rock</th>\n",
              "      <th>Item_Potassium chloride (muriate of potash) (MOP)</th>\n",
              "      <th>Item_Potassium nitrate</th>\n",
              "      <th>Item_Potassium sulphate (sulphate of potash) (SOP)</th>\n",
              "      <th>Item_Sodium nitrate</th>\n",
              "      <th>Item_Superphosphates above 35%</th>\n",
              "      <th>Item_Superphosphates, other</th>\n",
              "      <th>Item_Urea</th>\n",
              "      <th>Item_Urea and ammonium nitrate solutions (UAN)</th>\n",
              "      <th>Unit_tonnes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 175 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14cc0bff-adb8-4844-b7f4-4b640c2a0382')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14cc0bff-adb8-4844-b7f4-4b640c2a0382 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14cc0bff-adb8-4844-b7f4-4b640c2a0382');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5XEC9-Rr0IJ",
        "outputId": "0a579abe-7462-41e2-f9f4-f3a82b100307"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 146550 entries, 0 to 146549\n",
            "Columns: 175 entries, Year to Unit_tonnes\n",
            "dtypes: float64(1), int64(1), uint8(173)\n",
            "memory usage: 26.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y= df1['Value']"
      ],
      "metadata": {
        "id": "S1wQL7s4F91z"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(\"Value\",inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "mSdcdcGA_K2Z"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df2=pd.DataFrame(data=scaler.fit_transform(df1),columns=df1.columns)"
      ],
      "metadata": {
        "id": "vrJ3Py6Bv51p"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe()"
      ],
      "metadata": {
        "id": "_q74PeBqvflP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "2c648425-227a-4899-ce22-f260b6ea60a1"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Year   Area_Albania   Area_Algeria    Area_Angola  \\\n",
              "count  146550.000000  146550.000000  146550.000000  146550.000000   \n",
              "mean        0.516143       0.005827       0.006633       0.005329   \n",
              "std         0.302901       0.076115       0.081170       0.072807   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.266667       0.000000       0.000000       0.000000   \n",
              "50%         0.533333       0.000000       0.000000       0.000000   \n",
              "75%         0.800000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "       Area_Argentina   Area_Armenia  Area_Australia   Area_Austria  \\\n",
              "count   146550.000000  146550.000000   146550.000000  146550.000000   \n",
              "mean         0.009608       0.003978        0.009969       0.008461   \n",
              "std          0.097547       0.062947        0.099348       0.091596   \n",
              "min          0.000000       0.000000        0.000000       0.000000   \n",
              "25%          0.000000       0.000000        0.000000       0.000000   \n",
              "50%          0.000000       0.000000        0.000000       0.000000   \n",
              "75%          0.000000       0.000000        0.000000       0.000000   \n",
              "max          1.000000       1.000000        1.000000       1.000000   \n",
              "\n",
              "       Area_Azerbaijan   Area_Bahrain  ...  Item_Phosphate rock  \\\n",
              "count    146550.000000  146550.000000  ...        146550.000000   \n",
              "mean          0.005609       0.004817  ...             0.041494   \n",
              "std           0.074683       0.069241  ...             0.199431   \n",
              "min           0.000000       0.000000  ...             0.000000   \n",
              "25%           0.000000       0.000000  ...             0.000000   \n",
              "50%           0.000000       0.000000  ...             0.000000   \n",
              "75%           0.000000       0.000000  ...             0.000000   \n",
              "max           1.000000       1.000000  ...             1.000000   \n",
              "\n",
              "       Item_Potassium chloride (muriate of potash) (MOP)  \\\n",
              "count                                      146550.000000   \n",
              "mean                                            0.054159   \n",
              "std                                             0.226332   \n",
              "min                                             0.000000   \n",
              "25%                                             0.000000   \n",
              "50%                                             0.000000   \n",
              "75%                                             0.000000   \n",
              "max                                             1.000000   \n",
              "\n",
              "       Item_Potassium nitrate  \\\n",
              "count           146550.000000   \n",
              "mean                 0.046196   \n",
              "std                  0.209910   \n",
              "min                  0.000000   \n",
              "25%                  0.000000   \n",
              "50%                  0.000000   \n",
              "75%                  0.000000   \n",
              "max                  1.000000   \n",
              "\n",
              "       Item_Potassium sulphate (sulphate of potash) (SOP)  \\\n",
              "count                                      146550.000000    \n",
              "mean                                            0.047281    \n",
              "std                                             0.212240    \n",
              "min                                             0.000000    \n",
              "25%                                             0.000000    \n",
              "50%                                             0.000000    \n",
              "75%                                             0.000000    \n",
              "max                                             1.000000    \n",
              "\n",
              "       Item_Sodium nitrate  Item_Superphosphates above 35%  \\\n",
              "count        146550.000000                   146550.000000   \n",
              "mean              0.036035                        0.043896   \n",
              "std               0.186379                        0.204865   \n",
              "min               0.000000                        0.000000   \n",
              "25%               0.000000                        0.000000   \n",
              "50%               0.000000                        0.000000   \n",
              "75%               0.000000                        0.000000   \n",
              "max               1.000000                        1.000000   \n",
              "\n",
              "       Item_Superphosphates, other      Item_Urea  \\\n",
              "count                146550.000000  146550.000000   \n",
              "mean                      0.006844       0.064074   \n",
              "std                       0.082446       0.244885   \n",
              "min                       0.000000       0.000000   \n",
              "25%                       0.000000       0.000000   \n",
              "50%                       0.000000       0.000000   \n",
              "75%                       0.000000       0.000000   \n",
              "max                       1.000000       1.000000   \n",
              "\n",
              "       Item_Urea and ammonium nitrate solutions (UAN)    Unit_tonnes  \n",
              "count                                   146550.000000  146550.000000  \n",
              "mean                                         0.028243       0.566346  \n",
              "std                                          0.165667       0.495580  \n",
              "min                                          0.000000       0.000000  \n",
              "25%                                          0.000000       0.000000  \n",
              "50%                                          0.000000       1.000000  \n",
              "75%                                          0.000000       1.000000  \n",
              "max                                          1.000000       1.000000  \n",
              "\n",
              "[8 rows x 174 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04a320d7-1397-450c-ba7c-9ced58444367\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Area_Albania</th>\n",
              "      <th>Area_Algeria</th>\n",
              "      <th>Area_Angola</th>\n",
              "      <th>Area_Argentina</th>\n",
              "      <th>Area_Armenia</th>\n",
              "      <th>Area_Australia</th>\n",
              "      <th>Area_Austria</th>\n",
              "      <th>Area_Azerbaijan</th>\n",
              "      <th>Area_Bahrain</th>\n",
              "      <th>...</th>\n",
              "      <th>Item_Phosphate rock</th>\n",
              "      <th>Item_Potassium chloride (muriate of potash) (MOP)</th>\n",
              "      <th>Item_Potassium nitrate</th>\n",
              "      <th>Item_Potassium sulphate (sulphate of potash) (SOP)</th>\n",
              "      <th>Item_Sodium nitrate</th>\n",
              "      <th>Item_Superphosphates above 35%</th>\n",
              "      <th>Item_Superphosphates, other</th>\n",
              "      <th>Item_Urea</th>\n",
              "      <th>Item_Urea and ammonium nitrate solutions (UAN)</th>\n",
              "      <th>Unit_tonnes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "      <td>146550.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.516143</td>\n",
              "      <td>0.005827</td>\n",
              "      <td>0.006633</td>\n",
              "      <td>0.005329</td>\n",
              "      <td>0.009608</td>\n",
              "      <td>0.003978</td>\n",
              "      <td>0.009969</td>\n",
              "      <td>0.008461</td>\n",
              "      <td>0.005609</td>\n",
              "      <td>0.004817</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041494</td>\n",
              "      <td>0.054159</td>\n",
              "      <td>0.046196</td>\n",
              "      <td>0.047281</td>\n",
              "      <td>0.036035</td>\n",
              "      <td>0.043896</td>\n",
              "      <td>0.006844</td>\n",
              "      <td>0.064074</td>\n",
              "      <td>0.028243</td>\n",
              "      <td>0.566346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.302901</td>\n",
              "      <td>0.076115</td>\n",
              "      <td>0.081170</td>\n",
              "      <td>0.072807</td>\n",
              "      <td>0.097547</td>\n",
              "      <td>0.062947</td>\n",
              "      <td>0.099348</td>\n",
              "      <td>0.091596</td>\n",
              "      <td>0.074683</td>\n",
              "      <td>0.069241</td>\n",
              "      <td>...</td>\n",
              "      <td>0.199431</td>\n",
              "      <td>0.226332</td>\n",
              "      <td>0.209910</td>\n",
              "      <td>0.212240</td>\n",
              "      <td>0.186379</td>\n",
              "      <td>0.204865</td>\n",
              "      <td>0.082446</td>\n",
              "      <td>0.244885</td>\n",
              "      <td>0.165667</td>\n",
              "      <td>0.495580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 174 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04a320d7-1397-450c-ba7c-9ced58444367')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04a320d7-1397-450c-ba7c-9ced58444367 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04a320d7-1397-450c-ba7c-9ced58444367');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df2"
      ],
      "metadata": {
        "id": "5Yhzasl1F94q"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,Y.shape\n",
        "#print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EsDaLLnwYaf",
        "outputId": "3dba14c8-c72c-4729-ab64-a3beb01bacc4"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((146550, 174), (146550,))"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split into train and test datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=7)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6TKPaY4vf1i",
        "outputId": "e4b519f6-f622-4182-b936-d5a814da8e88"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(117240, 174) (29310, 174) (117240,) (29310,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = X_train.shape[1]  ## n_features =15\n",
        "n_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw0EbPzByle_",
        "outputId": "c8fd353a-1dde-4cca-f863-825fc3b0dd63"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "174"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model with 2 hidden layer\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(200, activation='relu', input_shape=(n_features,))) ##50,128\n",
        "model1.add(Dense(128, activation='relu'))\n",
        "model1.add(Dense(100, activation='relu')) #100,64 ,\n",
        "model1.add(Dense(1, activation='linear')) #"
      ],
      "metadata": {
        "id": "ppYwKHMyylk9"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model1.compile(optimizer='adam', loss=['mean_squared_error','mean_absolute_error'], metrics=['mae'])"
      ],
      "metadata": {
        "id": "F-gjJ6gHylop"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXKoJDmbzU7L",
        "outputId": "57618daa-31b2-40e9-8fd3-57ed0aecd328"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 200)               35000     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               25728     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               12900     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73,729\n",
            "Trainable params: 73,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model1.fit(X_train,Y_train,validation_split=0.2,epochs=500,batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrVhzo53zU_K",
        "outputId": "b5c199d8-e8ea-47d0-c204-b0ab9f42c327"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 465118593024.0000 - mae: 132542.6406 - val_loss: 408066719744.0000 - val_mae: 133776.5000\n",
            "Epoch 2/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 406869344256.0000 - mae: 121365.8984 - val_loss: 369392189440.0000 - val_mae: 112492.5234\n",
            "Epoch 3/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 373614313472.0000 - mae: 112124.0156 - val_loss: 348656467968.0000 - val_mae: 114326.8984\n",
            "Epoch 4/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 352800309248.0000 - mae: 110928.5547 - val_loss: 336630677504.0000 - val_mae: 110619.0234\n",
            "Epoch 5/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 338357092352.0000 - mae: 108298.2969 - val_loss: 330488905728.0000 - val_mae: 113336.7812\n",
            "Epoch 6/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 329440428032.0000 - mae: 107252.6484 - val_loss: 325572067328.0000 - val_mae: 106626.2344\n",
            "Epoch 7/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 322268823552.0000 - mae: 104967.4141 - val_loss: 321863942144.0000 - val_mae: 107605.6406\n",
            "Epoch 8/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 315751104512.0000 - mae: 103931.4766 - val_loss: 319356928000.0000 - val_mae: 107481.8281\n",
            "Epoch 9/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 310730817536.0000 - mae: 103053.5234 - val_loss: 315134836736.0000 - val_mae: 101488.0234\n",
            "Epoch 10/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 305488232448.0000 - mae: 101420.2734 - val_loss: 312261771264.0000 - val_mae: 103660.4922\n",
            "Epoch 11/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 301403930624.0000 - mae: 101120.5469 - val_loss: 309223555072.0000 - val_mae: 101279.7266\n",
            "Epoch 12/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 296948269056.0000 - mae: 100268.6016 - val_loss: 306701139968.0000 - val_mae: 99434.5703\n",
            "Epoch 13/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 292390633472.0000 - mae: 98801.1641 - val_loss: 306963873792.0000 - val_mae: 103328.7500\n",
            "Epoch 14/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 289335738368.0000 - mae: 98116.8125 - val_loss: 301748846592.0000 - val_mae: 99588.7500\n",
            "Epoch 15/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 285925670912.0000 - mae: 97795.8750 - val_loss: 299252613120.0000 - val_mae: 96749.1328\n",
            "Epoch 16/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 282423328768.0000 - mae: 95822.6484 - val_loss: 296555479040.0000 - val_mae: 98728.2656\n",
            "Epoch 17/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 279174053888.0000 - mae: 95513.1797 - val_loss: 293327994880.0000 - val_mae: 96998.5625\n",
            "Epoch 18/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 275281903616.0000 - mae: 94537.5078 - val_loss: 290989801472.0000 - val_mae: 95121.2734\n",
            "Epoch 19/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 271573712896.0000 - mae: 93959.7500 - val_loss: 290765406208.0000 - val_mae: 97448.3203\n",
            "Epoch 20/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 268800032768.0000 - mae: 92785.6953 - val_loss: 285189636096.0000 - val_mae: 93292.3516\n",
            "Epoch 21/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 265412952064.0000 - mae: 92103.6641 - val_loss: 283259863040.0000 - val_mae: 90757.4297\n",
            "Epoch 22/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 262064259072.0000 - mae: 90895.9922 - val_loss: 279908777984.0000 - val_mae: 91057.5781\n",
            "Epoch 23/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 258552184832.0000 - mae: 90600.1641 - val_loss: 276949499904.0000 - val_mae: 89770.2266\n",
            "Epoch 24/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 255382683648.0000 - mae: 89418.4688 - val_loss: 274156470272.0000 - val_mae: 88979.6484\n",
            "Epoch 25/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 251702296576.0000 - mae: 88659.4375 - val_loss: 270259011584.0000 - val_mae: 88673.8359\n",
            "Epoch 26/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 248274698240.0000 - mae: 87711.7734 - val_loss: 266936123392.0000 - val_mae: 88922.2500\n",
            "Epoch 27/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 243911983104.0000 - mae: 87090.6016 - val_loss: 264991588352.0000 - val_mae: 86066.9844\n",
            "Epoch 28/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 240080322560.0000 - mae: 85519.9219 - val_loss: 261155160064.0000 - val_mae: 85407.7969\n",
            "Epoch 29/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 236314001408.0000 - mae: 84935.7031 - val_loss: 257612677120.0000 - val_mae: 84831.0156\n",
            "Epoch 30/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 232415461376.0000 - mae: 84129.9297 - val_loss: 253923180544.0000 - val_mae: 85082.5547\n",
            "Epoch 31/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 228346249216.0000 - mae: 83286.8203 - val_loss: 251124498432.0000 - val_mae: 82519.0625\n",
            "Epoch 32/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 222206967808.0000 - mae: 82633.9922 - val_loss: 247061823488.0000 - val_mae: 84658.6719\n",
            "Epoch 33/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 218972438528.0000 - mae: 81370.2266 - val_loss: 243351420928.0000 - val_mae: 86489.5547\n",
            "Epoch 34/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 215107518464.0000 - mae: 81398.5625 - val_loss: 238898167808.0000 - val_mae: 81567.4453\n",
            "Epoch 35/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 210117902336.0000 - mae: 79943.6953 - val_loss: 235049959424.0000 - val_mae: 81302.0938\n",
            "Epoch 36/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 205591560192.0000 - mae: 79267.4844 - val_loss: 231920877568.0000 - val_mae: 79769.6953\n",
            "Epoch 37/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 200756789248.0000 - mae: 78284.1094 - val_loss: 227501539328.0000 - val_mae: 79879.6875\n",
            "Epoch 38/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 196484317184.0000 - mae: 77812.1641 - val_loss: 223287476224.0000 - val_mae: 79977.4375\n",
            "Epoch 39/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 191295553536.0000 - mae: 77137.7422 - val_loss: 220580446208.0000 - val_mae: 79709.2188\n",
            "Epoch 40/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 186914013184.0000 - mae: 76652.8359 - val_loss: 215605477376.0000 - val_mae: 77356.1641\n",
            "Epoch 41/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 181276164096.0000 - mae: 76057.0312 - val_loss: 213470412800.0000 - val_mae: 76029.2344\n",
            "Epoch 42/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 176289824768.0000 - mae: 75318.9297 - val_loss: 207190999040.0000 - val_mae: 76490.7734\n",
            "Epoch 43/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 171820646400.0000 - mae: 74796.4375 - val_loss: 202330636288.0000 - val_mae: 76594.8906\n",
            "Epoch 44/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 166841630720.0000 - mae: 74010.0312 - val_loss: 197883084800.0000 - val_mae: 75809.5156\n",
            "Epoch 45/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 161652015104.0000 - mae: 73313.8594 - val_loss: 195446259712.0000 - val_mae: 73740.8359\n",
            "Epoch 46/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 157696835584.0000 - mae: 72248.8281 - val_loss: 189284106240.0000 - val_mae: 74286.6484\n",
            "Epoch 47/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 151655677952.0000 - mae: 71368.0625 - val_loss: 184836685824.0000 - val_mae: 73743.5391\n",
            "Epoch 48/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 147160563712.0000 - mae: 70391.7500 - val_loss: 180637384704.0000 - val_mae: 72967.2578\n",
            "Epoch 49/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 143147401216.0000 - mae: 69395.0078 - val_loss: 176319774720.0000 - val_mae: 71323.6250\n",
            "Epoch 50/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 138624073728.0000 - mae: 68294.4219 - val_loss: 172959383552.0000 - val_mae: 69943.0938\n",
            "Epoch 51/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 134177603584.0000 - mae: 67294.7031 - val_loss: 168318353408.0000 - val_mae: 68905.3984\n",
            "Epoch 52/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 129749606400.0000 - mae: 66475.6250 - val_loss: 164058054656.0000 - val_mae: 67952.7031\n",
            "Epoch 53/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 124860596224.0000 - mae: 65720.0938 - val_loss: 159985369088.0000 - val_mae: 67973.7500\n",
            "Epoch 54/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 121221185536.0000 - mae: 65226.5938 - val_loss: 155041857536.0000 - val_mae: 66746.2656\n",
            "Epoch 55/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 116333322240.0000 - mae: 64301.4570 - val_loss: 151380557824.0000 - val_mae: 67814.8125\n",
            "Epoch 56/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 111708807168.0000 - mae: 63926.3906 - val_loss: 147715522560.0000 - val_mae: 65225.3516\n",
            "Epoch 57/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 107695603712.0000 - mae: 63197.9375 - val_loss: 141935886336.0000 - val_mae: 65047.6133\n",
            "Epoch 58/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 103292903424.0000 - mae: 62388.7148 - val_loss: 137657663488.0000 - val_mae: 65051.5664\n",
            "Epoch 59/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 98701950976.0000 - mae: 62011.8555 - val_loss: 135707164672.0000 - val_mae: 63789.0508\n",
            "Epoch 60/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 94733443072.0000 - mae: 61318.9648 - val_loss: 130248630272.0000 - val_mae: 63664.1211\n",
            "Epoch 61/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 91256406016.0000 - mae: 60609.8164 - val_loss: 126480039936.0000 - val_mae: 62750.2656\n",
            "Epoch 62/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 87404109824.0000 - mae: 60136.7461 - val_loss: 121889103872.0000 - val_mae: 62406.7891\n",
            "Epoch 63/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 83399376896.0000 - mae: 59506.4414 - val_loss: 119219347456.0000 - val_mae: 62511.4766\n",
            "Epoch 64/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 79839002624.0000 - mae: 58909.6133 - val_loss: 114423865344.0000 - val_mae: 61795.7109\n",
            "Epoch 65/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 76416999424.0000 - mae: 58331.3164 - val_loss: 112399015936.0000 - val_mae: 59965.4336\n",
            "Epoch 66/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 73184485376.0000 - mae: 57640.2695 - val_loss: 109265321984.0000 - val_mae: 60360.7734\n",
            "Epoch 67/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 70007029760.0000 - mae: 57158.9766 - val_loss: 107098865664.0000 - val_mae: 59140.1914\n",
            "Epoch 68/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 66671788032.0000 - mae: 56242.8125 - val_loss: 103458365440.0000 - val_mae: 59536.4023\n",
            "Epoch 69/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 63696576512.0000 - mae: 55713.3984 - val_loss: 100640694272.0000 - val_mae: 58135.9336\n",
            "Epoch 70/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 60597665792.0000 - mae: 54823.8320 - val_loss: 98114502656.0000 - val_mae: 57593.9961\n",
            "Epoch 71/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 58283159552.0000 - mae: 54068.2188 - val_loss: 95924584448.0000 - val_mae: 56710.8125\n",
            "Epoch 72/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 55396642816.0000 - mae: 53345.5664 - val_loss: 93609648128.0000 - val_mae: 56301.4062\n",
            "Epoch 73/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 52917731328.0000 - mae: 52887.8242 - val_loss: 92915662848.0000 - val_mae: 56432.3398\n",
            "Epoch 74/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 50944196608.0000 - mae: 52050.0039 - val_loss: 90030268416.0000 - val_mae: 54529.0430\n",
            "Epoch 75/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 48731938816.0000 - mae: 51263.0391 - val_loss: 90170834944.0000 - val_mae: 54563.0391\n",
            "Epoch 76/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 46812340224.0000 - mae: 50709.5469 - val_loss: 88220147712.0000 - val_mae: 53821.4453\n",
            "Epoch 77/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 44599070720.0000 - mae: 50200.7188 - val_loss: 88399790080.0000 - val_mae: 53444.6797\n",
            "Epoch 78/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 43104915456.0000 - mae: 49628.8242 - val_loss: 83904159744.0000 - val_mae: 53117.1875\n",
            "Epoch 79/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 41717293056.0000 - mae: 49051.0234 - val_loss: 83234127872.0000 - val_mae: 52222.9844\n",
            "Epoch 80/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 40290177024.0000 - mae: 48506.5352 - val_loss: 85421932544.0000 - val_mae: 51927.8828\n",
            "Epoch 81/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 38289268736.0000 - mae: 48034.1562 - val_loss: 81178853376.0000 - val_mae: 51596.9258\n",
            "Epoch 82/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 37387329536.0000 - mae: 47369.1016 - val_loss: 80391585792.0000 - val_mae: 50788.1875\n",
            "Epoch 83/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 36597743616.0000 - mae: 47027.5664 - val_loss: 81795465216.0000 - val_mae: 51267.7266\n",
            "Epoch 84/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 35053236224.0000 - mae: 46505.0664 - val_loss: 78944976896.0000 - val_mae: 50466.3086\n",
            "Epoch 85/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 34342858752.0000 - mae: 46152.8320 - val_loss: 78678491136.0000 - val_mae: 49989.8555\n",
            "Epoch 86/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 33013858304.0000 - mae: 45635.9688 - val_loss: 77954555904.0000 - val_mae: 50086.2188\n",
            "Epoch 87/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 32498534400.0000 - mae: 45325.6797 - val_loss: 77014761472.0000 - val_mae: 48720.7578\n",
            "Epoch 88/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 31224428544.0000 - mae: 44852.1016 - val_loss: 77346168832.0000 - val_mae: 49265.4688\n",
            "Epoch 89/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 30354507776.0000 - mae: 44549.4609 - val_loss: 76037758976.0000 - val_mae: 48076.1719\n",
            "Epoch 90/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 29832556544.0000 - mae: 44097.7852 - val_loss: 75053973504.0000 - val_mae: 48490.1367\n",
            "Epoch 91/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 28788822016.0000 - mae: 43799.1328 - val_loss: 77118414848.0000 - val_mae: 47539.9922\n",
            "Epoch 92/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 28412899328.0000 - mae: 43441.7383 - val_loss: 75320909824.0000 - val_mae: 47234.7773\n",
            "Epoch 93/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 28131739648.0000 - mae: 43108.9648 - val_loss: 74258325504.0000 - val_mae: 46287.8359\n",
            "Epoch 94/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 27313891328.0000 - mae: 42766.5078 - val_loss: 73324085248.0000 - val_mae: 46289.5781\n",
            "Epoch 95/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 26522365952.0000 - mae: 42450.4297 - val_loss: 71849484288.0000 - val_mae: 46265.6797\n",
            "Epoch 96/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 26375835648.0000 - mae: 42235.3164 - val_loss: 71591747584.0000 - val_mae: 45531.4492\n",
            "Epoch 97/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 25615826944.0000 - mae: 41633.6641 - val_loss: 71072161792.0000 - val_mae: 45421.5391\n",
            "Epoch 98/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 25179387904.0000 - mae: 41564.2734 - val_loss: 72441782272.0000 - val_mae: 45610.8594\n",
            "Epoch 99/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 24746762240.0000 - mae: 41310.1328 - val_loss: 70291292160.0000 - val_mae: 45162.7227\n",
            "Epoch 100/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 24224858112.0000 - mae: 41156.1836 - val_loss: 69211914240.0000 - val_mae: 44611.1680\n",
            "Epoch 101/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 23838679040.0000 - mae: 40692.1250 - val_loss: 69056946176.0000 - val_mae: 44831.6133\n",
            "Epoch 102/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 23540666368.0000 - mae: 40458.4219 - val_loss: 70698516480.0000 - val_mae: 44506.8711\n",
            "Epoch 103/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 23085594624.0000 - mae: 40352.3086 - val_loss: 68250464256.0000 - val_mae: 44140.6797\n",
            "Epoch 104/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 22887604224.0000 - mae: 40066.4492 - val_loss: 67599474688.0000 - val_mae: 43659.7539\n",
            "Epoch 105/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 22548281344.0000 - mae: 39957.6445 - val_loss: 68758994944.0000 - val_mae: 44385.7422\n",
            "Epoch 106/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 22481049600.0000 - mae: 39723.1836 - val_loss: 67614740480.0000 - val_mae: 43378.3008\n",
            "Epoch 107/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21842714624.0000 - mae: 39496.0039 - val_loss: 68304846848.0000 - val_mae: 43218.5234\n",
            "Epoch 108/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21872640000.0000 - mae: 39121.7500 - val_loss: 67739222016.0000 - val_mae: 43252.1992\n",
            "Epoch 109/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21626880000.0000 - mae: 38957.1016 - val_loss: 66939793408.0000 - val_mae: 43333.8281\n",
            "Epoch 110/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21641361408.0000 - mae: 39056.6367 - val_loss: 66684366848.0000 - val_mae: 42882.3516\n",
            "Epoch 111/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21349111808.0000 - mae: 38778.2891 - val_loss: 67115843584.0000 - val_mae: 42547.2305\n",
            "Epoch 112/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21000206336.0000 - mae: 38511.4609 - val_loss: 66254823424.0000 - val_mae: 42043.1289\n",
            "Epoch 113/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 21228832768.0000 - mae: 38522.1367 - val_loss: 65940869120.0000 - val_mae: 41981.2773\n",
            "Epoch 114/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 20616517632.0000 - mae: 38262.8984 - val_loss: 66443882496.0000 - val_mae: 42035.7500\n",
            "Epoch 115/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 20648642560.0000 - mae: 38187.0742 - val_loss: 64920334336.0000 - val_mae: 42376.2461\n",
            "Epoch 116/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 20254132224.0000 - mae: 37850.5312 - val_loss: 65672974336.0000 - val_mae: 42067.9102\n",
            "Epoch 117/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19965048832.0000 - mae: 37954.5938 - val_loss: 64463683584.0000 - val_mae: 41481.7969\n",
            "Epoch 118/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19953147904.0000 - mae: 37520.6875 - val_loss: 67534532608.0000 - val_mae: 42285.8516\n",
            "Epoch 119/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19926099968.0000 - mae: 37713.8750 - val_loss: 65444188160.0000 - val_mae: 41528.5469\n",
            "Epoch 120/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19837765632.0000 - mae: 37387.5547 - val_loss: 64918310912.0000 - val_mae: 41006.3789\n",
            "Epoch 121/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19519322112.0000 - mae: 37361.5938 - val_loss: 65871118336.0000 - val_mae: 42114.1250\n",
            "Epoch 122/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19685634048.0000 - mae: 37062.9180 - val_loss: 64570920960.0000 - val_mae: 40796.1992\n",
            "Epoch 123/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19331811328.0000 - mae: 37000.7266 - val_loss: 63934042112.0000 - val_mae: 40961.7031\n",
            "Epoch 124/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19396300800.0000 - mae: 36942.7109 - val_loss: 64011079680.0000 - val_mae: 40872.5469\n",
            "Epoch 125/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18982359040.0000 - mae: 36765.1562 - val_loss: 64899776512.0000 - val_mae: 40665.7539\n",
            "Epoch 126/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19010236416.0000 - mae: 36802.9727 - val_loss: 64022773760.0000 - val_mae: 40677.5625\n",
            "Epoch 127/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18806353920.0000 - mae: 36465.9883 - val_loss: 67193163776.0000 - val_mae: 41710.8477\n",
            "Epoch 128/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18846083072.0000 - mae: 36522.1172 - val_loss: 65973137408.0000 - val_mae: 40907.6367\n",
            "Epoch 129/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 19037708288.0000 - mae: 36393.6445 - val_loss: 64412958720.0000 - val_mae: 40943.5234\n",
            "Epoch 130/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18449221632.0000 - mae: 36392.9805 - val_loss: 63692853248.0000 - val_mae: 40479.1562\n",
            "Epoch 131/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18486501376.0000 - mae: 36319.1367 - val_loss: 65529589760.0000 - val_mae: 40413.7656\n",
            "Epoch 132/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18402840576.0000 - mae: 36083.9727 - val_loss: 63633477632.0000 - val_mae: 40617.1992\n",
            "Epoch 133/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18730274816.0000 - mae: 36264.5977 - val_loss: 64269094912.0000 - val_mae: 40454.6914\n",
            "Epoch 134/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18511249408.0000 - mae: 36116.1211 - val_loss: 64060108800.0000 - val_mae: 40090.5859\n",
            "Epoch 135/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18449811456.0000 - mae: 35821.1250 - val_loss: 64787918848.0000 - val_mae: 40187.1289\n",
            "Epoch 136/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18194499584.0000 - mae: 35882.2031 - val_loss: 65234456576.0000 - val_mae: 40821.6250\n",
            "Epoch 137/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18428393472.0000 - mae: 35679.0195 - val_loss: 63788847104.0000 - val_mae: 39906.9805\n",
            "Epoch 138/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18378250240.0000 - mae: 35606.0469 - val_loss: 66026700800.0000 - val_mae: 40602.5781\n",
            "Epoch 139/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17967284224.0000 - mae: 35577.7266 - val_loss: 63544475648.0000 - val_mae: 40258.8438\n",
            "Epoch 140/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18014900224.0000 - mae: 35610.8164 - val_loss: 64106881024.0000 - val_mae: 40029.2070\n",
            "Epoch 141/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17909176320.0000 - mae: 35522.1680 - val_loss: 63987093504.0000 - val_mae: 40579.6992\n",
            "Epoch 142/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 18032058368.0000 - mae: 35194.4883 - val_loss: 64490754048.0000 - val_mae: 40314.4062\n",
            "Epoch 143/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17728874496.0000 - mae: 35301.2773 - val_loss: 63210876928.0000 - val_mae: 39862.6094\n",
            "Epoch 144/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17669218304.0000 - mae: 35106.3242 - val_loss: 64249454592.0000 - val_mae: 39512.7695\n",
            "Epoch 145/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17867264000.0000 - mae: 35290.0781 - val_loss: 64443723776.0000 - val_mae: 40467.9492\n",
            "Epoch 146/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17653481472.0000 - mae: 35187.2031 - val_loss: 63708401664.0000 - val_mae: 39945.6797\n",
            "Epoch 147/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17633329152.0000 - mae: 34956.2461 - val_loss: 63614062592.0000 - val_mae: 39903.8320\n",
            "Epoch 148/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17235122176.0000 - mae: 35140.5703 - val_loss: 64823406592.0000 - val_mae: 39740.6250\n",
            "Epoch 149/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17811165184.0000 - mae: 34943.1250 - val_loss: 62978760704.0000 - val_mae: 39472.0703\n",
            "Epoch 150/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17472632832.0000 - mae: 34996.0352 - val_loss: 65486270464.0000 - val_mae: 40996.9805\n",
            "Epoch 151/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17218830336.0000 - mae: 34675.2188 - val_loss: 64548605952.0000 - val_mae: 39336.2305\n",
            "Epoch 152/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17267828736.0000 - mae: 34825.9492 - val_loss: 62180102144.0000 - val_mae: 38526.2500\n",
            "Epoch 153/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17349367808.0000 - mae: 34577.2734 - val_loss: 62732001280.0000 - val_mae: 39006.1133\n",
            "Epoch 154/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17388961792.0000 - mae: 34633.1016 - val_loss: 63316258816.0000 - val_mae: 39175.9258\n",
            "Epoch 155/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16895579136.0000 - mae: 34481.6367 - val_loss: 63909670912.0000 - val_mae: 39407.8086\n",
            "Epoch 156/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17310406656.0000 - mae: 34473.0273 - val_loss: 63170953216.0000 - val_mae: 39297.0117\n",
            "Epoch 157/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17113600000.0000 - mae: 34454.6055 - val_loss: 64232546304.0000 - val_mae: 39192.1562\n",
            "Epoch 158/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17021615104.0000 - mae: 34354.9375 - val_loss: 63595053056.0000 - val_mae: 39292.1680\n",
            "Epoch 159/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16862829568.0000 - mae: 34151.8242 - val_loss: 64792395776.0000 - val_mae: 39233.4648\n",
            "Epoch 160/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17086714880.0000 - mae: 34365.8477 - val_loss: 63417483264.0000 - val_mae: 38836.6719\n",
            "Epoch 161/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16915453952.0000 - mae: 34307.9531 - val_loss: 62221221888.0000 - val_mae: 38569.0898\n",
            "Epoch 162/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16651419648.0000 - mae: 34043.5195 - val_loss: 63412969472.0000 - val_mae: 38781.1250\n",
            "Epoch 163/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16957517824.0000 - mae: 34123.1172 - val_loss: 61973188608.0000 - val_mae: 38757.4297\n",
            "Epoch 164/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16822597632.0000 - mae: 34153.3281 - val_loss: 63676514304.0000 - val_mae: 38731.3398\n",
            "Epoch 165/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16727619584.0000 - mae: 33943.3867 - val_loss: 62830403584.0000 - val_mae: 38749.5586\n",
            "Epoch 166/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16610257920.0000 - mae: 33745.5664 - val_loss: 63491280896.0000 - val_mae: 38882.7891\n",
            "Epoch 167/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 17047061504.0000 - mae: 34138.1836 - val_loss: 63204519936.0000 - val_mae: 40486.7539\n",
            "Epoch 168/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 16684433408.0000 - mae: 33952.0312 - val_loss: 62589628416.0000 - val_mae: 39299.7188\n",
            "Epoch 169/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16678086656.0000 - mae: 33869.4766 - val_loss: 62806958080.0000 - val_mae: 38626.9961\n",
            "Epoch 170/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16237007872.0000 - mae: 33672.3359 - val_loss: 64522825728.0000 - val_mae: 38610.6484\n",
            "Epoch 171/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16706178048.0000 - mae: 33781.9219 - val_loss: 62016110592.0000 - val_mae: 38178.6406\n",
            "Epoch 172/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16587634688.0000 - mae: 33862.6875 - val_loss: 64596541440.0000 - val_mae: 40338.8945\n",
            "Epoch 173/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16418181120.0000 - mae: 33633.0938 - val_loss: 62922207232.0000 - val_mae: 38295.7500\n",
            "Epoch 174/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16384693248.0000 - mae: 33754.1211 - val_loss: 61570232320.0000 - val_mae: 37907.5547\n",
            "Epoch 175/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16478945280.0000 - mae: 33460.1484 - val_loss: 62673670144.0000 - val_mae: 37843.9375\n",
            "Epoch 176/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16477343744.0000 - mae: 33616.7383 - val_loss: 62068092928.0000 - val_mae: 38837.6406\n",
            "Epoch 177/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16587560960.0000 - mae: 33440.2578 - val_loss: 61839523840.0000 - val_mae: 38039.5312\n",
            "Epoch 178/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16391790592.0000 - mae: 33350.9922 - val_loss: 62884458496.0000 - val_mae: 39556.3242\n",
            "Epoch 179/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16315625472.0000 - mae: 33342.2812 - val_loss: 62958452736.0000 - val_mae: 38844.1367\n",
            "Epoch 180/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16257438720.0000 - mae: 33303.7695 - val_loss: 62091132928.0000 - val_mae: 37738.7031\n",
            "Epoch 181/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16379602944.0000 - mae: 33352.3672 - val_loss: 63257563136.0000 - val_mae: 38618.8164\n",
            "Epoch 182/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16221828096.0000 - mae: 33286.5273 - val_loss: 64198443008.0000 - val_mae: 39050.1523\n",
            "Epoch 183/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16538730496.0000 - mae: 33310.4297 - val_loss: 63146082304.0000 - val_mae: 38333.1758\n",
            "Epoch 184/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16204326912.0000 - mae: 33186.9141 - val_loss: 61955596288.0000 - val_mae: 37727.3398\n",
            "Epoch 185/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16321174528.0000 - mae: 33324.7109 - val_loss: 63950839808.0000 - val_mae: 38834.9766\n",
            "Epoch 186/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16146701312.0000 - mae: 33192.5195 - val_loss: 62408581120.0000 - val_mae: 38297.5820\n",
            "Epoch 187/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16394628096.0000 - mae: 33238.0898 - val_loss: 62078656512.0000 - val_mae: 37846.6562\n",
            "Epoch 188/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16385242112.0000 - mae: 33023.0352 - val_loss: 63369052160.0000 - val_mae: 38940.7188\n",
            "Epoch 189/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16207713280.0000 - mae: 32972.1484 - val_loss: 62271324160.0000 - val_mae: 38243.4922\n",
            "Epoch 190/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15857584128.0000 - mae: 33189.0547 - val_loss: 62782742528.0000 - val_mae: 38088.9844\n",
            "Epoch 191/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16041325568.0000 - mae: 33124.3281 - val_loss: 61334294528.0000 - val_mae: 37514.3438\n",
            "Epoch 192/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 16055042048.0000 - mae: 32937.9883 - val_loss: 62361518080.0000 - val_mae: 38103.3164\n",
            "Epoch 193/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15970292736.0000 - mae: 32919.9258 - val_loss: 62497533952.0000 - val_mae: 37930.7422\n",
            "Epoch 194/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15926414336.0000 - mae: 33073.2734 - val_loss: 62910812160.0000 - val_mae: 38410.9922\n",
            "Epoch 195/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15931759616.0000 - mae: 33013.2695 - val_loss: 62442209280.0000 - val_mae: 37512.2305\n",
            "Epoch 196/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15906642944.0000 - mae: 32554.0938 - val_loss: 63408820224.0000 - val_mae: 38025.6875\n",
            "Epoch 197/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15397278720.0000 - mae: 32960.6289 - val_loss: 61548621824.0000 - val_mae: 37642.8242\n",
            "Epoch 198/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15931250688.0000 - mae: 32830.8477 - val_loss: 62399504384.0000 - val_mae: 37641.5234\n",
            "Epoch 199/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15729244160.0000 - mae: 32698.1582 - val_loss: 61712068608.0000 - val_mae: 37793.4805\n",
            "Epoch 200/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15994005504.0000 - mae: 32730.2793 - val_loss: 62254473216.0000 - val_mae: 37653.0508\n",
            "Epoch 201/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15507159040.0000 - mae: 32463.7344 - val_loss: 61452480512.0000 - val_mae: 37734.7539\n",
            "Epoch 202/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15960569856.0000 - mae: 32619.7441 - val_loss: 62251954176.0000 - val_mae: 37412.3828\n",
            "Epoch 203/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15893356544.0000 - mae: 32401.6699 - val_loss: 61941268480.0000 - val_mae: 37558.2188\n",
            "Epoch 204/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 15389044736.0000 - mae: 32408.3320 - val_loss: 62721814528.0000 - val_mae: 38313.6328\n",
            "Epoch 205/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15710682112.0000 - mae: 32594.4531 - val_loss: 62924812288.0000 - val_mae: 38174.7891\n",
            "Epoch 206/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15490130944.0000 - mae: 32424.1504 - val_loss: 62168682496.0000 - val_mae: 37391.1094\n",
            "Epoch 207/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15599778816.0000 - mae: 32348.3867 - val_loss: 61542510592.0000 - val_mae: 37150.3594\n",
            "Epoch 208/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15689893888.0000 - mae: 32428.7402 - val_loss: 62653702144.0000 - val_mae: 38000.0117\n",
            "Epoch 209/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15492692992.0000 - mae: 32526.5703 - val_loss: 61702840320.0000 - val_mae: 37220.9180\n",
            "Epoch 210/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15652545536.0000 - mae: 32247.1211 - val_loss: 61620420608.0000 - val_mae: 37077.4648\n",
            "Epoch 211/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15551264768.0000 - mae: 32134.9297 - val_loss: 63020052480.0000 - val_mae: 37680.4570\n",
            "Epoch 212/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15384674304.0000 - mae: 32392.6309 - val_loss: 61474258944.0000 - val_mae: 37217.3164\n",
            "Epoch 213/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15330502656.0000 - mae: 32289.6895 - val_loss: 62760464384.0000 - val_mae: 37875.7578\n",
            "Epoch 214/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15395771392.0000 - mae: 32441.1074 - val_loss: 62096871424.0000 - val_mae: 37715.3086\n",
            "Epoch 215/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15361921024.0000 - mae: 32209.1523 - val_loss: 61065060352.0000 - val_mae: 37036.7930\n",
            "Epoch 216/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15386036224.0000 - mae: 32255.9805 - val_loss: 62279688192.0000 - val_mae: 37715.7109\n",
            "Epoch 217/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15420973056.0000 - mae: 32140.2188 - val_loss: 61807247360.0000 - val_mae: 37440.9570\n",
            "Epoch 218/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15227159552.0000 - mae: 32120.7422 - val_loss: 61966434304.0000 - val_mae: 37460.1133\n",
            "Epoch 219/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15420152832.0000 - mae: 32051.1738 - val_loss: 62572171264.0000 - val_mae: 37170.2422\n",
            "Epoch 220/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15557691392.0000 - mae: 32064.2402 - val_loss: 61388787712.0000 - val_mae: 37105.7617\n",
            "Epoch 221/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15210390528.0000 - mae: 31859.7695 - val_loss: 63341981696.0000 - val_mae: 37561.0703\n",
            "Epoch 222/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15277724672.0000 - mae: 32125.4922 - val_loss: 61458165760.0000 - val_mae: 36924.9922\n",
            "Epoch 223/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15198752768.0000 - mae: 31868.1602 - val_loss: 60862377984.0000 - val_mae: 36477.3789\n",
            "Epoch 224/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15158980608.0000 - mae: 31912.9805 - val_loss: 62292164608.0000 - val_mae: 37112.8477\n",
            "Epoch 225/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15161263104.0000 - mae: 31737.4297 - val_loss: 65845161984.0000 - val_mae: 40014.9609\n",
            "Epoch 226/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15350306816.0000 - mae: 31833.9023 - val_loss: 62325137408.0000 - val_mae: 38175.2812\n",
            "Epoch 227/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15309286400.0000 - mae: 31803.5977 - val_loss: 61144559616.0000 - val_mae: 36660.2539\n",
            "Epoch 228/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15305706496.0000 - mae: 31761.0020 - val_loss: 61881761792.0000 - val_mae: 36898.3555\n",
            "Epoch 229/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14844067840.0000 - mae: 31644.7578 - val_loss: 63674257408.0000 - val_mae: 37530.3438\n",
            "Epoch 230/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15384105984.0000 - mae: 31721.3711 - val_loss: 62204391424.0000 - val_mae: 36928.0664\n",
            "Epoch 231/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15047417856.0000 - mae: 31496.1523 - val_loss: 62017548288.0000 - val_mae: 36659.1914\n",
            "Epoch 232/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15065119744.0000 - mae: 31495.8281 - val_loss: 61418123264.0000 - val_mae: 37412.6602\n",
            "Epoch 233/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15219817472.0000 - mae: 31656.5449 - val_loss: 61200883712.0000 - val_mae: 36940.1016\n",
            "Epoch 234/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 15284008960.0000 - mae: 31545.0234 - val_loss: 61097238528.0000 - val_mae: 36375.3359\n",
            "Epoch 235/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15057316864.0000 - mae: 31591.7715 - val_loss: 61553991680.0000 - val_mae: 36822.2812\n",
            "Epoch 236/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14938109952.0000 - mae: 31457.0840 - val_loss: 62714966016.0000 - val_mae: 36832.1836\n",
            "Epoch 237/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15112624128.0000 - mae: 31381.8438 - val_loss: 61794177024.0000 - val_mae: 36425.8242\n",
            "Epoch 238/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15123249152.0000 - mae: 31597.7969 - val_loss: 61830373376.0000 - val_mae: 36530.3164\n",
            "Epoch 239/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 14880281600.0000 - mae: 31450.4844 - val_loss: 62264623104.0000 - val_mae: 36887.9961\n",
            "Epoch 240/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15039749120.0000 - mae: 31626.6523 - val_loss: 62154182656.0000 - val_mae: 36523.2656\n",
            "Epoch 241/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14830954496.0000 - mae: 31374.2812 - val_loss: 63670194176.0000 - val_mae: 37168.5703\n",
            "Epoch 242/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14807285760.0000 - mae: 31424.7910 - val_loss: 61921091584.0000 - val_mae: 36603.8359\n",
            "Epoch 243/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15043614720.0000 - mae: 31398.8027 - val_loss: 61502537728.0000 - val_mae: 36368.7656\n",
            "Epoch 244/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14694210560.0000 - mae: 31279.6562 - val_loss: 62442868736.0000 - val_mae: 36532.2773\n",
            "Epoch 245/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14940653568.0000 - mae: 31272.3965 - val_loss: 61779300352.0000 - val_mae: 36963.3945\n",
            "Epoch 246/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14772656128.0000 - mae: 31351.5586 - val_loss: 61576908800.0000 - val_mae: 36814.6875\n",
            "Epoch 247/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 15141151744.0000 - mae: 31346.2930 - val_loss: 61169713152.0000 - val_mae: 36343.4961\n",
            "Epoch 248/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14727736320.0000 - mae: 31244.6406 - val_loss: 61410836480.0000 - val_mae: 36344.5039\n",
            "Epoch 249/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14829704192.0000 - mae: 31219.8125 - val_loss: 60966187008.0000 - val_mae: 36054.8438\n",
            "Epoch 250/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14811008000.0000 - mae: 31095.1465 - val_loss: 61555462144.0000 - val_mae: 36763.7383\n",
            "Epoch 251/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14716067840.0000 - mae: 31190.8340 - val_loss: 62258647040.0000 - val_mae: 36280.5039\n",
            "Epoch 252/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14720162816.0000 - mae: 31259.7285 - val_loss: 61040836608.0000 - val_mae: 36228.5938\n",
            "Epoch 253/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14708362240.0000 - mae: 31218.6719 - val_loss: 61298200576.0000 - val_mae: 36520.6797\n",
            "Epoch 254/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14540813312.0000 - mae: 30883.2754 - val_loss: 63559233536.0000 - val_mae: 36909.1523\n",
            "Epoch 255/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14629142528.0000 - mae: 31062.1758 - val_loss: 62032953344.0000 - val_mae: 36827.2148\n",
            "Epoch 256/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14913371136.0000 - mae: 31085.9531 - val_loss: 61723144192.0000 - val_mae: 36915.9688\n",
            "Epoch 257/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14748350464.0000 - mae: 31208.9043 - val_loss: 62922829824.0000 - val_mae: 37145.1055\n",
            "Epoch 258/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14709586944.0000 - mae: 30936.8262 - val_loss: 62608519168.0000 - val_mae: 36492.4648\n",
            "Epoch 259/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14757991424.0000 - mae: 30900.6270 - val_loss: 62731051008.0000 - val_mae: 36667.5156\n",
            "Epoch 260/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14564654080.0000 - mae: 31099.0605 - val_loss: 60618428416.0000 - val_mae: 36099.9258\n",
            "Epoch 261/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14528216064.0000 - mae: 30983.0156 - val_loss: 61386567680.0000 - val_mae: 35892.2227\n",
            "Epoch 262/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14617768960.0000 - mae: 30965.6660 - val_loss: 63388192768.0000 - val_mae: 36828.6055\n",
            "Epoch 263/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14500914176.0000 - mae: 30894.9629 - val_loss: 61584470016.0000 - val_mae: 36394.3320\n",
            "Epoch 264/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14470055936.0000 - mae: 30806.2285 - val_loss: 62095716352.0000 - val_mae: 36246.7188\n",
            "Epoch 265/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14549835776.0000 - mae: 30966.5020 - val_loss: 62706667520.0000 - val_mae: 36527.3516\n",
            "Epoch 266/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14528526336.0000 - mae: 30920.9531 - val_loss: 62544269312.0000 - val_mae: 36823.2617\n",
            "Epoch 267/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14335633408.0000 - mae: 31038.6660 - val_loss: 60785262592.0000 - val_mae: 36619.3867\n",
            "Epoch 268/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14511315968.0000 - mae: 30939.9883 - val_loss: 61937692672.0000 - val_mae: 36840.4023\n",
            "Epoch 269/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14348527616.0000 - mae: 30866.9609 - val_loss: 60613189632.0000 - val_mae: 36260.5977\n",
            "Epoch 270/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14616256512.0000 - mae: 30800.8262 - val_loss: 62509080576.0000 - val_mae: 36646.8789\n",
            "Epoch 271/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14508993536.0000 - mae: 30597.4043 - val_loss: 60643270656.0000 - val_mae: 36010.1836\n",
            "Epoch 272/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14463007744.0000 - mae: 30591.0918 - val_loss: 61617246208.0000 - val_mae: 36145.4844\n",
            "Epoch 273/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14434762752.0000 - mae: 30607.4922 - val_loss: 60619956224.0000 - val_mae: 36792.1055\n",
            "Epoch 274/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14359681024.0000 - mae: 30540.7461 - val_loss: 61740544000.0000 - val_mae: 36430.3203\n",
            "Epoch 275/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14601230336.0000 - mae: 30756.4023 - val_loss: 62177095680.0000 - val_mae: 36279.7109\n",
            "Epoch 276/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14569913344.0000 - mae: 30583.6855 - val_loss: 62297313280.0000 - val_mae: 36782.8047\n",
            "Epoch 277/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14413330432.0000 - mae: 30553.2969 - val_loss: 62316359680.0000 - val_mae: 36552.6055\n",
            "Epoch 278/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14503911424.0000 - mae: 30550.2578 - val_loss: 62370263040.0000 - val_mae: 36115.0664\n",
            "Epoch 279/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14438116352.0000 - mae: 30547.7891 - val_loss: 61489446912.0000 - val_mae: 36281.6094\n",
            "Epoch 280/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14512765952.0000 - mae: 30615.2363 - val_loss: 61370109952.0000 - val_mae: 36606.1562\n",
            "Epoch 281/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14574103552.0000 - mae: 30488.3496 - val_loss: 61751758848.0000 - val_mae: 35934.1484\n",
            "Epoch 282/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14397296640.0000 - mae: 30455.1289 - val_loss: 60881018880.0000 - val_mae: 36159.7695\n",
            "Epoch 283/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14353415168.0000 - mae: 30463.7383 - val_loss: 60964052992.0000 - val_mae: 36374.0000\n",
            "Epoch 284/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14221722624.0000 - mae: 30378.7480 - val_loss: 62473973760.0000 - val_mae: 36802.7617\n",
            "Epoch 285/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14492271616.0000 - mae: 30324.1016 - val_loss: 61247463424.0000 - val_mae: 35962.4336\n",
            "Epoch 286/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14269767680.0000 - mae: 30372.1406 - val_loss: 61714223104.0000 - val_mae: 36164.2188\n",
            "Epoch 287/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14067771392.0000 - mae: 30408.1328 - val_loss: 60709748736.0000 - val_mae: 36465.2188\n",
            "Epoch 288/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14189435904.0000 - mae: 30306.3633 - val_loss: 62509117440.0000 - val_mae: 36044.3164\n",
            "Epoch 289/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14099574784.0000 - mae: 30388.6406 - val_loss: 61409722368.0000 - val_mae: 37210.9141\n",
            "Epoch 290/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14260098048.0000 - mae: 30312.0742 - val_loss: 63137628160.0000 - val_mae: 36171.8281\n",
            "Epoch 291/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14150388736.0000 - mae: 30341.0391 - val_loss: 60691222528.0000 - val_mae: 35686.3164\n",
            "Epoch 292/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14589075456.0000 - mae: 30240.9941 - val_loss: 61210013696.0000 - val_mae: 35659.9648\n",
            "Epoch 293/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14244317184.0000 - mae: 30322.3828 - val_loss: 60067434496.0000 - val_mae: 35451.1680\n",
            "Epoch 294/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14299609088.0000 - mae: 30207.4414 - val_loss: 60480425984.0000 - val_mae: 36168.5859\n",
            "Epoch 295/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14175153152.0000 - mae: 30190.0781 - val_loss: 62761492480.0000 - val_mae: 36197.4258\n",
            "Epoch 296/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14237993984.0000 - mae: 30098.3770 - val_loss: 62492635136.0000 - val_mae: 36319.3438\n",
            "Epoch 297/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14043524096.0000 - mae: 30060.2188 - val_loss: 61012639744.0000 - val_mae: 36113.1016\n",
            "Epoch 298/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14180894720.0000 - mae: 30194.5430 - val_loss: 60268470272.0000 - val_mae: 35834.5781\n",
            "Epoch 299/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14180028416.0000 - mae: 30043.8789 - val_loss: 60980199424.0000 - val_mae: 36194.7852\n",
            "Epoch 300/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14067457024.0000 - mae: 30242.1777 - val_loss: 61345665024.0000 - val_mae: 36836.2617\n",
            "Epoch 301/500\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 13972730880.0000 - mae: 29987.6035 - val_loss: 60498976768.0000 - val_mae: 35939.3008\n",
            "Epoch 302/500\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 14106002432.0000 - mae: 29906.6309 - val_loss: 62156349440.0000 - val_mae: 36137.6641\n",
            "Epoch 303/500\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 14088321024.0000 - mae: 30121.8633 - val_loss: 61643841536.0000 - val_mae: 35953.6602\n",
            "Epoch 304/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 14206885888.0000 - mae: 30082.8008 - val_loss: 61584822272.0000 - val_mae: 35854.0742\n",
            "Epoch 305/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13886371840.0000 - mae: 29870.2344 - val_loss: 61261520896.0000 - val_mae: 35809.0117\n",
            "Epoch 306/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14007060480.0000 - mae: 30063.9785 - val_loss: 61989982208.0000 - val_mae: 36128.6719\n",
            "Epoch 307/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 14138011648.0000 - mae: 29977.5977 - val_loss: 61043687424.0000 - val_mae: 35936.0234\n",
            "Epoch 308/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13916212224.0000 - mae: 29902.7754 - val_loss: 60583030784.0000 - val_mae: 36167.9414\n",
            "Epoch 309/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13895575552.0000 - mae: 30030.1133 - val_loss: 61967962112.0000 - val_mae: 35572.2031\n",
            "Epoch 310/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 14020084736.0000 - mae: 29938.7734 - val_loss: 61393420288.0000 - val_mae: 36168.3945\n",
            "Epoch 311/500\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 13891383296.0000 - mae: 29894.7227 - val_loss: 60400627712.0000 - val_mae: 35839.9219\n",
            "Epoch 312/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 14098734080.0000 - mae: 29974.2227 - val_loss: 61068034048.0000 - val_mae: 35991.4922\n",
            "Epoch 313/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 14096822272.0000 - mae: 29885.3828 - val_loss: 61356666880.0000 - val_mae: 35751.3867\n",
            "Epoch 314/500\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 13863988224.0000 - mae: 29879.5664 - val_loss: 60561440768.0000 - val_mae: 35143.8242\n",
            "Epoch 315/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13769589760.0000 - mae: 29745.0117 - val_loss: 60155912192.0000 - val_mae: 35207.6406\n",
            "Epoch 316/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13805956096.0000 - mae: 29667.8516 - val_loss: 60878221312.0000 - val_mae: 35797.8047\n",
            "Epoch 317/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 14172431360.0000 - mae: 29893.6191 - val_loss: 60568719360.0000 - val_mae: 35648.9375\n",
            "Epoch 318/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 14076175360.0000 - mae: 29839.2715 - val_loss: 62004424704.0000 - val_mae: 35606.2773\n",
            "Epoch 319/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 13760579584.0000 - mae: 29687.4844 - val_loss: 61245743104.0000 - val_mae: 35299.0156\n",
            "Epoch 320/500\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 13932775424.0000 - mae: 29884.0293 - val_loss: 61176139776.0000 - val_mae: 35616.4922\n",
            "Epoch 321/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13891013632.0000 - mae: 29641.0977 - val_loss: 61896278016.0000 - val_mae: 36298.7773\n",
            "Epoch 322/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13775944704.0000 - mae: 29514.9590 - val_loss: 61461737472.0000 - val_mae: 35981.9219\n",
            "Epoch 323/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13592053760.0000 - mae: 29666.9668 - val_loss: 60529115136.0000 - val_mae: 36525.9297\n",
            "Epoch 324/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13876477952.0000 - mae: 29611.8594 - val_loss: 60699435008.0000 - val_mae: 35984.1289\n",
            "Epoch 325/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13931065344.0000 - mae: 29737.4336 - val_loss: 61872300032.0000 - val_mae: 36489.1094\n",
            "Epoch 326/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 13478824960.0000 - mae: 29480.5410 - val_loss: 62234992640.0000 - val_mae: 36586.5039\n",
            "Epoch 327/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 14064939008.0000 - mae: 29713.5586 - val_loss: 60647116800.0000 - val_mae: 35353.9023\n",
            "Epoch 328/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13933345792.0000 - mae: 29500.8613 - val_loss: 61285941248.0000 - val_mae: 35512.7656\n",
            "Epoch 329/500\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 13726592000.0000 - mae: 29610.9414 - val_loss: 61458223104.0000 - val_mae: 35969.8281\n",
            "Epoch 330/500\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 13630981120.0000 - mae: 29596.2422 - val_loss: 61676044288.0000 - val_mae: 35740.0586\n",
            "Epoch 331/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13724532736.0000 - mae: 29573.4258 - val_loss: 60601606144.0000 - val_mae: 34991.2148\n",
            "Epoch 332/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 13676362752.0000 - mae: 29404.1426 - val_loss: 62622294016.0000 - val_mae: 36245.2305\n",
            "Epoch 333/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13817103360.0000 - mae: 29535.5078 - val_loss: 61007245312.0000 - val_mae: 35744.3359\n",
            "Epoch 334/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 13686706176.0000 - mae: 29479.8926 - val_loss: 60614320128.0000 - val_mae: 35156.3789\n",
            "Epoch 335/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13744569344.0000 - mae: 29476.7812 - val_loss: 60425252864.0000 - val_mae: 35514.2461\n",
            "Epoch 336/500\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 13757810688.0000 - mae: 29502.7422 - val_loss: 61393494016.0000 - val_mae: 35626.9570\n",
            "Epoch 337/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13612972032.0000 - mae: 29299.5020 - val_loss: 62611283968.0000 - val_mae: 37210.4023\n",
            "Epoch 338/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13580345344.0000 - mae: 29196.9434 - val_loss: 61827379200.0000 - val_mae: 35881.3203\n",
            "Epoch 339/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13648556032.0000 - mae: 29336.3027 - val_loss: 63556059136.0000 - val_mae: 36105.3008\n",
            "Epoch 340/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13877257216.0000 - mae: 29361.1816 - val_loss: 62406942720.0000 - val_mae: 35555.0664\n",
            "Epoch 341/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13485392896.0000 - mae: 29045.3301 - val_loss: 62961537024.0000 - val_mae: 36354.0508\n",
            "Epoch 342/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13760423936.0000 - mae: 29418.1133 - val_loss: 62365966336.0000 - val_mae: 35910.6094\n",
            "Epoch 343/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13679136768.0000 - mae: 29341.6172 - val_loss: 62314119168.0000 - val_mae: 35357.2266\n",
            "Epoch 344/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13767108608.0000 - mae: 29169.3105 - val_loss: 61100068864.0000 - val_mae: 36498.6406\n",
            "Epoch 345/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13866617856.0000 - mae: 29231.7070 - val_loss: 62844215296.0000 - val_mae: 35702.2422\n",
            "Epoch 346/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13400559616.0000 - mae: 29241.2988 - val_loss: 60410626048.0000 - val_mae: 34906.0664\n",
            "Epoch 347/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13296623616.0000 - mae: 29134.6953 - val_loss: 60773240832.0000 - val_mae: 35026.1523\n",
            "Epoch 348/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13595127808.0000 - mae: 29101.6934 - val_loss: 60533813248.0000 - val_mae: 35395.6953\n",
            "Epoch 349/500\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 13537358848.0000 - mae: 29004.1348 - val_loss: 61030584320.0000 - val_mae: 36007.1797\n",
            "Epoch 350/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13643917312.0000 - mae: 29182.2305 - val_loss: 62800228352.0000 - val_mae: 35640.8516\n",
            "Epoch 351/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13685408768.0000 - mae: 29078.1191 - val_loss: 61464322048.0000 - val_mae: 35433.7812\n",
            "Epoch 352/500\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 13617196032.0000 - mae: 28950.3359 - val_loss: 61503447040.0000 - val_mae: 35260.2500\n",
            "Epoch 353/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13380728832.0000 - mae: 29080.0195 - val_loss: 60408299520.0000 - val_mae: 34794.1562\n",
            "Epoch 354/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13451941888.0000 - mae: 28965.8867 - val_loss: 60553654272.0000 - val_mae: 35265.3750\n",
            "Epoch 355/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13441537024.0000 - mae: 28855.4297 - val_loss: 61189115904.0000 - val_mae: 35469.9180\n",
            "Epoch 356/500\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 13312950272.0000 - mae: 28989.5957 - val_loss: 60562481152.0000 - val_mae: 35050.1758\n",
            "Epoch 357/500\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 13263598592.0000 - mae: 28992.6680 - val_loss: 60108804096.0000 - val_mae: 34954.4414\n",
            "Epoch 358/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13475906560.0000 - mae: 28946.1758 - val_loss: 60935483392.0000 - val_mae: 35600.3516\n",
            "Epoch 359/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13692081152.0000 - mae: 29138.0234 - val_loss: 60849618944.0000 - val_mae: 35824.4570\n",
            "Epoch 360/500\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 13646161920.0000 - mae: 28989.2617 - val_loss: 60745228288.0000 - val_mae: 35077.1055\n",
            "Epoch 361/500\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 13466956800.0000 - mae: 28715.3164 - val_loss: 63232077824.0000 - val_mae: 36763.4531\n",
            "Epoch 362/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13478063104.0000 - mae: 29019.8711 - val_loss: 59601207296.0000 - val_mae: 34679.2148\n",
            "Epoch 363/500\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 13450714112.0000 - mae: 28822.3223 - val_loss: 61451440128.0000 - val_mae: 35611.2344\n",
            "Epoch 364/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13581319168.0000 - mae: 28984.5293 - val_loss: 61343854592.0000 - val_mae: 35391.4688\n",
            "Epoch 365/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 13459164160.0000 - mae: 28819.2051 - val_loss: 62302961664.0000 - val_mae: 34861.5781\n",
            "Epoch 366/500\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 13522479104.0000 - mae: 28852.5234 - val_loss: 60808568832.0000 - val_mae: 34850.1250\n",
            "Epoch 367/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 13505550336.0000 - mae: 28747.5234 - val_loss: 60751437824.0000 - val_mae: 34716.0508\n",
            "Epoch 368/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13486218240.0000 - mae: 28634.2129 - val_loss: 60999929856.0000 - val_mae: 35916.1602\n",
            "Epoch 369/500\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 13556713472.0000 - mae: 28771.5020 - val_loss: 61533614080.0000 - val_mae: 35255.5312\n",
            "Epoch 370/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13180646400.0000 - mae: 28728.8223 - val_loss: 61527519232.0000 - val_mae: 35639.9688\n",
            "Epoch 371/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13342816256.0000 - mae: 28777.4746 - val_loss: 61006340096.0000 - val_mae: 35172.9688\n",
            "Epoch 372/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13569648640.0000 - mae: 28638.4258 - val_loss: 60489486336.0000 - val_mae: 34453.7500\n",
            "Epoch 373/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13265666048.0000 - mae: 28809.3789 - val_loss: 60774465536.0000 - val_mae: 34826.6016\n",
            "Epoch 374/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13269403648.0000 - mae: 28563.7285 - val_loss: 60547522560.0000 - val_mae: 34860.7969\n",
            "Epoch 375/500\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 13451446272.0000 - mae: 28833.9922 - val_loss: 60652830720.0000 - val_mae: 35261.5977\n",
            "Epoch 376/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13245717504.0000 - mae: 28600.7852 - val_loss: 60527501312.0000 - val_mae: 34871.6875\n",
            "Epoch 377/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13175472128.0000 - mae: 28514.8379 - val_loss: 61719752704.0000 - val_mae: 35047.8398\n",
            "Epoch 378/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13402669056.0000 - mae: 28589.6777 - val_loss: 61258235904.0000 - val_mae: 35190.3242\n",
            "Epoch 379/500\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 13192054784.0000 - mae: 28512.4473 - val_loss: 60708536320.0000 - val_mae: 34521.8164\n",
            "Epoch 380/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13253826560.0000 - mae: 28412.3008 - val_loss: 59811393536.0000 - val_mae: 34896.3086\n",
            "Epoch 381/500\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 13322229760.0000 - mae: 28615.5957 - val_loss: 61205987328.0000 - val_mae: 34516.4180\n",
            "Epoch 382/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13378016256.0000 - mae: 28732.7500 - val_loss: 60416327680.0000 - val_mae: 34886.7734\n",
            "Epoch 383/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13354238976.0000 - mae: 28685.0664 - val_loss: 61813125120.0000 - val_mae: 35280.2852\n",
            "Epoch 384/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13273510912.0000 - mae: 28490.4355 - val_loss: 59934466048.0000 - val_mae: 33991.7930\n",
            "Epoch 385/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13443163136.0000 - mae: 28471.0938 - val_loss: 60795609088.0000 - val_mae: 34760.8359\n",
            "Epoch 386/500\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 13276751872.0000 - mae: 28433.3594 - val_loss: 61093806080.0000 - val_mae: 34978.3633\n",
            "Epoch 387/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13189101568.0000 - mae: 28504.0879 - val_loss: 61051228160.0000 - val_mae: 34934.5547\n",
            "Epoch 388/500\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 13161463808.0000 - mae: 28463.3184 - val_loss: 61704196096.0000 - val_mae: 36400.2656\n",
            "Epoch 389/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13268558848.0000 - mae: 28513.0762 - val_loss: 61108658176.0000 - val_mae: 34934.8828\n",
            "Epoch 390/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13100389376.0000 - mae: 28484.4453 - val_loss: 61657980928.0000 - val_mae: 35769.8320\n",
            "Epoch 391/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13224005632.0000 - mae: 28423.3203 - val_loss: 60870533120.0000 - val_mae: 34283.6484\n",
            "Epoch 392/500\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 13221576704.0000 - mae: 28474.3438 - val_loss: 62514987008.0000 - val_mae: 36534.8281\n",
            "Epoch 393/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13170413568.0000 - mae: 28391.8926 - val_loss: 60621008896.0000 - val_mae: 35123.6953\n",
            "Epoch 394/500\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 13365578752.0000 - mae: 28503.0801 - val_loss: 60826611712.0000 - val_mae: 34904.3047\n",
            "Epoch 395/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 13185708032.0000 - mae: 28419.0410 - val_loss: 60296654848.0000 - val_mae: 34641.9609\n",
            "Epoch 396/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13114813440.0000 - mae: 28180.1660 - val_loss: 59900092416.0000 - val_mae: 34636.5391\n",
            "Epoch 397/500\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 13153480704.0000 - mae: 28326.7285 - val_loss: 60954161152.0000 - val_mae: 35346.5039\n",
            "Epoch 398/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13153464320.0000 - mae: 28375.4355 - val_loss: 61149638656.0000 - val_mae: 34715.1758\n",
            "Epoch 399/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13224726528.0000 - mae: 28429.1641 - val_loss: 60318552064.0000 - val_mae: 34426.0625\n",
            "Epoch 400/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13169665024.0000 - mae: 28285.8730 - val_loss: 61735735296.0000 - val_mae: 35091.6289\n",
            "Epoch 401/500\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 13287014400.0000 - mae: 28264.2422 - val_loss: 59826778112.0000 - val_mae: 34450.7852\n",
            "Epoch 402/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 13110000640.0000 - mae: 28319.2422 - val_loss: 61478285312.0000 - val_mae: 35096.2617\n",
            "Epoch 403/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12957352960.0000 - mae: 28338.9258 - val_loss: 60049141760.0000 - val_mae: 34566.2500\n",
            "Epoch 404/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 13222055936.0000 - mae: 28271.4551 - val_loss: 61549043712.0000 - val_mae: 35718.9844\n",
            "Epoch 405/500\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 13040363520.0000 - mae: 28330.2109 - val_loss: 59696848896.0000 - val_mae: 34643.1758\n",
            "Epoch 406/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13215111168.0000 - mae: 28216.4062 - val_loss: 61314416640.0000 - val_mae: 35218.6641\n",
            "Epoch 407/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13120253952.0000 - mae: 28238.1270 - val_loss: 60387606528.0000 - val_mae: 34824.2812\n",
            "Epoch 408/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13075658752.0000 - mae: 28391.0254 - val_loss: 61493669888.0000 - val_mae: 35146.8906\n",
            "Epoch 409/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13124482048.0000 - mae: 28428.8203 - val_loss: 60786720768.0000 - val_mae: 35105.6055\n",
            "Epoch 410/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13203216384.0000 - mae: 28160.8730 - val_loss: 60900642816.0000 - val_mae: 34652.5430\n",
            "Epoch 411/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13068107776.0000 - mae: 28030.8613 - val_loss: 60162306048.0000 - val_mae: 34945.0039\n",
            "Epoch 412/500\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 13206874112.0000 - mae: 28183.9922 - val_loss: 61429825536.0000 - val_mae: 35520.8086\n",
            "Epoch 413/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13159400448.0000 - mae: 28201.6230 - val_loss: 61955325952.0000 - val_mae: 34715.5000\n",
            "Epoch 414/500\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 13090401280.0000 - mae: 28050.8711 - val_loss: 61529333760.0000 - val_mae: 35683.0898\n",
            "Epoch 415/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12969938944.0000 - mae: 27923.6934 - val_loss: 60073664512.0000 - val_mae: 34461.1602\n",
            "Epoch 416/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 13041430528.0000 - mae: 28118.9922 - val_loss: 59954552832.0000 - val_mae: 34109.7148\n",
            "Epoch 417/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 13109821440.0000 - mae: 27965.6934 - val_loss: 60462333952.0000 - val_mae: 34278.4180\n",
            "Epoch 418/500\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 13004590080.0000 - mae: 27930.7949 - val_loss: 60434354176.0000 - val_mae: 34613.9180\n",
            "Epoch 419/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 12800885760.0000 - mae: 27863.9648 - val_loss: 61439651840.0000 - val_mae: 34827.8750\n",
            "Epoch 420/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12856017920.0000 - mae: 28167.5215 - val_loss: 60174491648.0000 - val_mae: 34474.6133\n",
            "Epoch 421/500\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 13020583936.0000 - mae: 28143.1973 - val_loss: 61472444416.0000 - val_mae: 34601.1953\n",
            "Epoch 422/500\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 12818651136.0000 - mae: 28006.2422 - val_loss: 59600543744.0000 - val_mae: 34662.8633\n",
            "Epoch 423/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13025744896.0000 - mae: 28041.7715 - val_loss: 60705644544.0000 - val_mae: 34822.7539\n",
            "Epoch 424/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 13063441408.0000 - mae: 28099.1582 - val_loss: 59398483968.0000 - val_mae: 34561.3359\n",
            "Epoch 425/500\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 12930885632.0000 - mae: 28036.8809 - val_loss: 60742205440.0000 - val_mae: 34542.5742\n",
            "Epoch 426/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12871852032.0000 - mae: 27887.1289 - val_loss: 61310279680.0000 - val_mae: 34703.5820\n",
            "Epoch 427/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12911577088.0000 - mae: 27920.9609 - val_loss: 60078854144.0000 - val_mae: 34498.3125\n",
            "Epoch 428/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12743026688.0000 - mae: 27747.9941 - val_loss: 62361202688.0000 - val_mae: 34974.0078\n",
            "Epoch 429/500\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 12846397440.0000 - mae: 28006.2227 - val_loss: 60607111168.0000 - val_mae: 34234.3594\n",
            "Epoch 430/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12855976960.0000 - mae: 27736.1230 - val_loss: 59843604480.0000 - val_mae: 34080.1953\n",
            "Epoch 431/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12817411072.0000 - mae: 27909.7051 - val_loss: 60013568000.0000 - val_mae: 34677.3320\n",
            "Epoch 432/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12945166336.0000 - mae: 27791.0859 - val_loss: 60481589248.0000 - val_mae: 34364.6523\n",
            "Epoch 433/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 13049236480.0000 - mae: 27835.4414 - val_loss: 61409189888.0000 - val_mae: 34494.7891\n",
            "Epoch 434/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12604041216.0000 - mae: 27657.3867 - val_loss: 59543093248.0000 - val_mae: 34406.0469\n",
            "Epoch 435/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12947188736.0000 - mae: 27711.7324 - val_loss: 60591919104.0000 - val_mae: 34460.4961\n",
            "Epoch 436/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 12809462784.0000 - mae: 27943.4844 - val_loss: 60322082816.0000 - val_mae: 34564.1016\n",
            "Epoch 437/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12817091584.0000 - mae: 27790.2715 - val_loss: 61072928768.0000 - val_mae: 35245.1406\n",
            "Epoch 438/500\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 12988304384.0000 - mae: 27840.8047 - val_loss: 60036206592.0000 - val_mae: 33953.3008\n",
            "Epoch 439/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12858316800.0000 - mae: 27828.7246 - val_loss: 61140578304.0000 - val_mae: 34702.1914\n",
            "Epoch 440/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 12554390528.0000 - mae: 27684.3887 - val_loss: 60443369472.0000 - val_mae: 34924.4102\n",
            "Epoch 441/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12785175552.0000 - mae: 27782.3496 - val_loss: 60207353856.0000 - val_mae: 35181.1602\n",
            "Epoch 442/500\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 12798377984.0000 - mae: 28016.8184 - val_loss: 59650162688.0000 - val_mae: 34321.6445\n",
            "Epoch 443/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12898665472.0000 - mae: 27778.7832 - val_loss: 59774177280.0000 - val_mae: 33962.7852\n",
            "Epoch 444/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12889963520.0000 - mae: 27574.1094 - val_loss: 61138247680.0000 - val_mae: 35707.4336\n",
            "Epoch 445/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 12685783040.0000 - mae: 27729.3535 - val_loss: 61106511872.0000 - val_mae: 35282.5391\n",
            "Epoch 446/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12744011776.0000 - mae: 27820.9160 - val_loss: 60271497216.0000 - val_mae: 34726.9180\n",
            "Epoch 447/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 12863613952.0000 - mae: 27889.7305 - val_loss: 59436908544.0000 - val_mae: 34423.4688\n",
            "Epoch 448/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12779863040.0000 - mae: 27676.8457 - val_loss: 59700604928.0000 - val_mae: 34218.5586\n",
            "Epoch 449/500\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 12597643264.0000 - mae: 27601.2305 - val_loss: 59826102272.0000 - val_mae: 34263.3438\n",
            "Epoch 450/500\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 12791621632.0000 - mae: 27737.4004 - val_loss: 60461703168.0000 - val_mae: 35218.5430\n",
            "Epoch 451/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12789312512.0000 - mae: 27707.7344 - val_loss: 60365316096.0000 - val_mae: 34202.5000\n",
            "Epoch 452/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 13044810752.0000 - mae: 27742.7793 - val_loss: 59909160960.0000 - val_mae: 34532.4336\n",
            "Epoch 453/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 12789996544.0000 - mae: 27666.0605 - val_loss: 59804426240.0000 - val_mae: 34091.7266\n",
            "Epoch 454/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12702987264.0000 - mae: 27586.2812 - val_loss: 61567979520.0000 - val_mae: 33892.9297\n",
            "Epoch 455/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12510935040.0000 - mae: 27589.9688 - val_loss: 59259633664.0000 - val_mae: 33881.7773\n",
            "Epoch 456/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12680554496.0000 - mae: 27585.2285 - val_loss: 60372852736.0000 - val_mae: 34296.7109\n",
            "Epoch 457/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12480913408.0000 - mae: 27627.6055 - val_loss: 59008466944.0000 - val_mae: 34128.9844\n",
            "Epoch 458/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 12932828160.0000 - mae: 27720.3027 - val_loss: 59577331712.0000 - val_mae: 33812.0859\n",
            "Epoch 459/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12760531968.0000 - mae: 27455.8691 - val_loss: 61558079488.0000 - val_mae: 35680.2188\n",
            "Epoch 460/500\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 12551223296.0000 - mae: 27616.7539 - val_loss: 59384147968.0000 - val_mae: 34219.9922\n",
            "Epoch 461/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12916853760.0000 - mae: 27614.1133 - val_loss: 60022898688.0000 - val_mae: 34436.9102\n",
            "Epoch 462/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12571905024.0000 - mae: 27472.0078 - val_loss: 60164190208.0000 - val_mae: 34681.8086\n",
            "Epoch 463/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 12652068864.0000 - mae: 27546.9102 - val_loss: 59852836864.0000 - val_mae: 34071.6797\n",
            "Epoch 464/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 12544922624.0000 - mae: 27473.4766 - val_loss: 59877335040.0000 - val_mae: 34437.0664\n",
            "Epoch 465/500\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 12443189248.0000 - mae: 27805.7734 - val_loss: 60846010368.0000 - val_mae: 34754.0781\n",
            "Epoch 466/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12528638976.0000 - mae: 27525.1758 - val_loss: 59683426304.0000 - val_mae: 34210.6406\n",
            "Epoch 467/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12618309632.0000 - mae: 27407.0254 - val_loss: 60408418304.0000 - val_mae: 34019.5391\n",
            "Epoch 468/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12765373440.0000 - mae: 27684.4863 - val_loss: 59840659456.0000 - val_mae: 34273.9062\n",
            "Epoch 469/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 12684521472.0000 - mae: 27476.0938 - val_loss: 59953876992.0000 - val_mae: 34216.9375\n",
            "Epoch 470/500\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 12743162880.0000 - mae: 27490.9277 - val_loss: 60241240064.0000 - val_mae: 33963.5547\n",
            "Epoch 471/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12557861888.0000 - mae: 27433.4883 - val_loss: 60659961856.0000 - val_mae: 34487.6719\n",
            "Epoch 472/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12525797376.0000 - mae: 27296.6641 - val_loss: 59943751680.0000 - val_mae: 34851.9141\n",
            "Epoch 473/500\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 12523632640.0000 - mae: 27384.5684 - val_loss: 61312372736.0000 - val_mae: 34139.6797\n",
            "Epoch 474/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 12768158720.0000 - mae: 27265.9102 - val_loss: 59822587904.0000 - val_mae: 34003.0938\n",
            "Epoch 475/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 12463567872.0000 - mae: 27349.1426 - val_loss: 60975517696.0000 - val_mae: 34285.3672\n",
            "Epoch 476/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12383457280.0000 - mae: 27266.1172 - val_loss: 59889004544.0000 - val_mae: 34561.9141\n",
            "Epoch 477/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 12553371648.0000 - mae: 27356.0859 - val_loss: 61720420352.0000 - val_mae: 33999.5508\n",
            "Epoch 478/500\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 12476488704.0000 - mae: 27407.0312 - val_loss: 60827361280.0000 - val_mae: 34755.4297\n",
            "Epoch 479/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 12638652416.0000 - mae: 27355.6191 - val_loss: 60945879040.0000 - val_mae: 35503.4961\n",
            "Epoch 480/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 12548321280.0000 - mae: 27271.2656 - val_loss: 59840327680.0000 - val_mae: 33815.0625\n",
            "Epoch 481/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12494022656.0000 - mae: 27202.1406 - val_loss: 60011184128.0000 - val_mae: 33924.7617\n",
            "Epoch 482/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 12520414208.0000 - mae: 27221.4941 - val_loss: 60292112384.0000 - val_mae: 33887.7578\n",
            "Epoch 483/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 12469833728.0000 - mae: 27178.6367 - val_loss: 60499992576.0000 - val_mae: 33956.7695\n",
            "Epoch 484/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 12584327168.0000 - mae: 27378.2637 - val_loss: 61570826240.0000 - val_mae: 33908.7539\n",
            "Epoch 485/500\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 12458454016.0000 - mae: 27326.5254 - val_loss: 59514040320.0000 - val_mae: 33657.3555\n",
            "Epoch 486/500\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 12505171968.0000 - mae: 27376.8242 - val_loss: 61404766208.0000 - val_mae: 34275.8359\n",
            "Epoch 487/500\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 12354387968.0000 - mae: 27224.6113 - val_loss: 59335626752.0000 - val_mae: 34015.0625\n",
            "Epoch 488/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12687891456.0000 - mae: 27378.0859 - val_loss: 60187697152.0000 - val_mae: 34216.2227\n",
            "Epoch 489/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12276476928.0000 - mae: 27094.7090 - val_loss: 60853997568.0000 - val_mae: 33834.5547\n",
            "Epoch 490/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12577388544.0000 - mae: 27189.3770 - val_loss: 59653427200.0000 - val_mae: 33880.4492\n",
            "Epoch 491/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12351763456.0000 - mae: 27047.8125 - val_loss: 60397043712.0000 - val_mae: 34789.3867\n",
            "Epoch 492/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12325209088.0000 - mae: 27132.4688 - val_loss: 59118862336.0000 - val_mae: 33865.6992\n",
            "Epoch 493/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 12468567040.0000 - mae: 27243.9199 - val_loss: 60201340928.0000 - val_mae: 33718.9336\n",
            "Epoch 494/500\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 12430214144.0000 - mae: 27214.7109 - val_loss: 63437062144.0000 - val_mae: 36283.9922\n",
            "Epoch 495/500\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 12278909952.0000 - mae: 27229.2305 - val_loss: 62239686656.0000 - val_mae: 34886.8633\n",
            "Epoch 496/500\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 12602939392.0000 - mae: 27272.2324 - val_loss: 60327964672.0000 - val_mae: 35183.0000\n",
            "Epoch 497/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12367645696.0000 - mae: 27231.7852 - val_loss: 60057292800.0000 - val_mae: 33865.2188\n",
            "Epoch 498/500\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 12348391424.0000 - mae: 27110.9746 - val_loss: 59083296768.0000 - val_mae: 33492.6992\n",
            "Epoch 499/500\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 12503107584.0000 - mae: 27120.2207 - val_loss: 59399770112.0000 - val_mae: 33748.0352\n",
            "Epoch 500/500\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 12404521984.0000 - mae: 27069.0723 - val_loss: 60108546048.0000 - val_mae: 33378.6875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict on test data\n",
        "predictions=model1.predict(X_test[:5])\n",
        "print(\"Predicted values are: \",predictions)\n",
        "print(\"Real value are: \",Y_test[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8dahVUw6Psx",
        "outputId": "37c6a946-18bc-4091-8319-ad0ca6f1e7c6"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted values are:  [[ 8719.481 ]\n",
            " [14529.089 ]\n",
            " [ 1310.1111]\n",
            " [ 5666.002 ]\n",
            " [ 1310.1108]]\n",
            "Real value are:  145666        0.00\n",
            "81706     82216.14\n",
            "94045       114.71\n",
            "123093      109.00\n",
            "141486      125.77\n",
            "Name: Value, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_nn = model1.predict(X_test)\n",
        "y_pred_nn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8d8jxXB0uUb",
        "outputId": "e1e9d5f9-7563-4ec9-f1b3-e0ab6f920b10"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8719.481 ],\n",
              "       [14529.089 ],\n",
              "       [ 1310.1111],\n",
              "       ...,\n",
              "       [ 5066.6685],\n",
              "       [-1718.7476],\n",
              "       [ 1310.1111]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(Y_test,y_pred_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "bXpa6dYa0unR",
        "outputId": "23987f68-46c3-4757-fbc2-45fb8d888067"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f12c68ffc10>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_fun(Y_test,Y_pred):\n",
        "  from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "  r2 = r2_score(Y_test,Y_pred)\n",
        "  mse = mean_squared_error(Y_test,Y_pred)\n",
        "  mae = mean_absolute_error(Y_test,Y_pred)\n",
        "  return r2,mse,mae\n",
        "#r2,mse,mae for NN model\n",
        "r2,mse,mae = eval_fun(Y_test,y_pred_nn)\n",
        "print(\"r2 score: \",r2,\"mean_squared_error: \",mse,\"mean_absolute_error: \",mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5xjwYbwzVGN",
        "outputId": "84b66a9e-da55-4410-ecf6-53a0bbb5b435"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2 score:  0.7226724531507274 mean_squared_error:  127240731494.27417 mean_absolute_error:  35600.356929500296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##plot the training and validation loss at each epochs\n",
        "from matplotlib import pyplot as plt\n",
        "loss = history.history['loss']\n",
        "val_loss= history.history['val_loss']\n",
        "epochs=range(1,len(loss) + 1) #range(1,35)\n",
        "plt.plot(epochs,loss,'y',label='Training loss')\n",
        "plt.plot(epochs,val_loss,'r',label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "FFd0ptBr2rXz",
        "outputId": "a71735b8-904b-45ea-975b-be3d178302e7"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "mae = history.history['mae']\n",
        "val_mae= history.history['val_mae']\n",
        "epochs=range(1,len(loss) + 1) #range(1,11)\n",
        "plt.plot(epochs,mae,'y',label='Training MAE')\n",
        "plt.plot(epochs,val_mae,'r',label='Validation MAE')\n",
        "plt.title('Training and Validation MAE')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BkAocxTS2rfD",
        "outputId": "cebfc99c-a5b9-4ce1-a3e4-4071140d3e20"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,acc = model1.evaluate(X_test,Y_test,verbose=0)\n",
        "print(\"Accuracy: %.4f\" %acc)\n",
        "print(\"loss: %.4f\" %loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkZjyGeLzVCx",
        "outputId": "94ddaa59-7035-4530-90de-d9674f8c3810"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 35600.3555\n",
            "loss: 127240904704.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y_test,Y_pred):\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "  import numpy as np\n",
        "  mse = mean_squared_error(Y_test,Y_pred)\n",
        "  rmse=np.sqrt(mse)\n",
        "  return rmse\n",
        "rmse(Y_test,y_pred_nn)"
      ],
      "metadata": {
        "id": "4dVun3pM5ENk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b9e9d3-6032-44a4-ef31-2a96cc904dfe"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "356708.1881514274"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "pickle.dump(model1,open(\"Model1.pkl\",'wb'))\n",
        "#loading the save model\n",
        "Model = pickle.load(open(\"Model1.pkl\",'rb'))\n"
      ],
      "metadata": {
        "id": "Xbm0oXa9vf8h"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8lFIFLtYhtzQ"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C5anNXB-ht2q"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2l5suwB75EKK"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7CjSO5jb5EGh"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0dC6Ew0t5ECd"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRhCJBs25D8t"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from kerastuner.tuners import RandomSearch"
      ],
      "metadata": {
        "id": "YH-dCLIv-CMu"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfHbgsNl2jTI",
        "outputId": "cfd05d33-aacf-40f7-9c2c-2bf7614a8474"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 15.3 MB/s \n",
            "\u001b[?25hCollecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.2.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.48.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#layer,neuron,learning rate\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    for i in range(hp.Int('num_layers', 2, 50)):\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),min_value=32,max_value=512,step=32),activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='linear'))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),loss='mean_absolute_error',metrics=['mean_absolute_error'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "O0InSHz52jY6"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(build_model,objective='val_mean_absolute_error',max_trials=5,executions_per_trial=3,directory='project',project_name='Value')"
      ],
      "metadata": {
        "id": "8sgKGjYT2jeL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "bf696fc2-746c-422b-e467-7f871d7360f0"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-4acfe8b635ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexecutions_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'project'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomSearch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "uAmRolRY2ji7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "AIiw4Pf02joj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, Y_train,epochs=5,validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "id": "zFXCUguDJr0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "id": "QEoSaAfxJr3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZgBea6WsJr6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Flask in google colab\n"
      ],
      "metadata": {
        "id": "IgiDyJws6DIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok"
      ],
      "metadata": {
        "id": "RF1Wg1bv2ju1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "##running the flask app\n",
        "app=Flask(__name__)\n",
        "##when the app is run that time ngrok should be already start\n",
        "run_with_ngrok(app)\n",
        "@app.route('/')\n",
        "def index():\n",
        "  return \"<h1>Trail of Flask on google colab!</h1>\"\n",
        "@app.route(\"/get_details\")\n",
        "def get_details():\n",
        "  return \"<h1>This is the get details page!</h1>\"\n",
        "@app.route(\"/test\")\n",
        "def test_page():\n",
        "  return \"<h1>This is Test page!</h1>\"\n",
        "\n",
        "app.run()\n"
      ],
      "metadata": {
        "id": "njoa4DEbvgGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWBcTGeX57p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_XHVL4-57tk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}